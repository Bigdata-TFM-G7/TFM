{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Classification with Amazon review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Gathering Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "input_file = \"Clothing_Shoes_and_Jewelry_5.json\"\n",
    "input_json = open(input_file, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "output_file = \"Clothing_Shoes_and_Jewelry_5.csv\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as output_csv:\n",
    "    csv_writer = csv.writer(output_csv)\n",
    "    flag = 0\n",
    "    for line in input_json.readlines():\n",
    "        dic = json.loads(line)\n",
    "        # writing headline in the beginning\n",
    "        if flag == 0:\n",
    "            csv_writer.writerow(dic)\n",
    "            flag = 1\n",
    "        csv_writer.writerow(dic.values())\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "input_data = pd.read_csv(\"Clothing_Shoes_and_Jewelry_5.csv\")\n",
    "input_data['overall'] = input_data['overall'].astype(object) # fix datatype error\n",
    "input_data['reviewText'] = input_data['reviewText'].astype(object) # fix datatype error\n",
    "\n",
    "dataset = {\"reviewText\": input_data[\"reviewText\"], \"overall\": input_data[\"overall\"]  }\n",
    "dataset = pd.DataFrame(data = dataset)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "dataset = dataset[dataset[\"overall\"] != '3'] # need datatype=object\n",
    "dataset[\"label\"] = dataset[\"overall\"].apply(lambda rating : +1 if str(rating) > '3' else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText overall  label\n",
       "0  This is a great tutu and at a really great pri...     5.0      1\n",
       "1  I bought this for my 4 yr old daughter for dan...     5.0      1\n",
       "2  What can I say... my daughters have it in oran...     5.0      1\n",
       "3  We bought several tutus at once, and they are ...     5.0      1\n",
       "4  Thank you Halo Heaven great product for Little...     5.0      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "278672    1\n",
       "278673    1\n",
       "278674    1\n",
       "278675    1\n",
       "278676    1\n",
       "Name: label, Length: 278653, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset into Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Añadir dos columnas, el txtclean, donde va a trajar el texto y vamos a limpiar los textos de espacios y demás\n",
    "X = pd.DataFrame(dataset, columns = [\"reviewText\"])\n",
    "y = pd.DataFrame(dataset, columns = [\"label\"])\n",
    "\n",
    "#Separa en train y test los datos, random_state es la semilla de un numero aletrorio\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               reviewText\n",
      "0       This is a great tutu and at a really great pri...\n",
      "1       I bought this for my 4 yr old daughter for dan...\n",
      "2       What can I say... my daughters have it in oran...\n",
      "3       We bought several tutus at once, and they are ...\n",
      "4       Thank you Halo Heaven great product for Little...\n",
      "...                                                   ...\n",
      "278672  I don't normally go ga-ga over a product very ...\n",
      "278673  I've been traveling back and forth to England ...\n",
      "278674  These are very nice packing cubes and the 18 x...\n",
      "278675  I am on vacation with my family of four and th...\n",
      "278676  When I signed up to receive a free set of Shac...\n",
      "\n",
      "[278653 rows x 1 columns]         label\n",
      "0           1\n",
      "1           1\n",
      "2           1\n",
      "3           1\n",
      "4           1\n",
      "...       ...\n",
      "278672      1\n",
      "278673      1\n",
      "278674      1\n",
      "278675      1\n",
      "278676      1\n",
      "\n",
      "[278653 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               reviewText\n",
      "250767  well made and nice looking too. I lovee this I...\n",
      "110585  I have a wide foot, New Balance is the only co...\n",
      "46414   I love doc martens but these are so stiff and ...\n",
      "126255  I wasn't really sure which size I would be I a...\n",
      "96195   Quality of material very poor.  I should have ...\n",
      "...                                                   ...\n",
      "165976  This item is not a sweater, but rather a fairl...\n",
      "186480  I recently bought 10-15 Patty items, after rea...\n",
      "153726  I have been looking for a fleece &#34;closed b...\n",
      "239522  These earrings have a nice shape, but I had th...\n",
      "103917  I like the New Balance MW978. the only Issue t...\n",
      "\n",
      "[208989 rows x 1 columns]                                                reviewText\n",
      "2640    The tiny screws that hold the lid on fell out ...\n",
      "238515  As like I said before Gerber has great product...\n",
      "172625  These are a little big but cute i still rock t...\n",
      "220153  Horrible pants, I can't stand the polyester fa...\n",
      "192134  I just love this colorful tote.  Fits my perso...\n",
      "...                                                   ...\n",
      "249026  i like the fit as well as the shimmer of the l...\n",
      "233452  These socks are so soft and silky. they keep m...\n",
      "59957   Just got them in the mail yesterday and I real...\n",
      "270455  I wear a size 12 and I purchased this in an x-...\n",
      "97014   I love this long sleeve.  Body conscious, comf...\n",
      "\n",
      "[69664 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "? train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label\n",
      "250767      1\n",
      "110585      1\n",
      "46414      -1\n",
      "126255      1\n",
      "96195      -1\n",
      "...       ...\n",
      "165976      1\n",
      "186480      1\n",
      "153726      1\n",
      "239522      1\n",
      "103917      1\n",
      "\n",
      "[208989 rows x 1 columns]         label\n",
      "2640       -1\n",
      "238515      1\n",
      "172625      1\n",
      "220153     -1\n",
      "192134      1\n",
      "...       ...\n",
      "249026      1\n",
      "233452      1\n",
      "59957       1\n",
      "270455      1\n",
      "97014       1\n",
      "\n",
      "[69664 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_y, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Step: Text Data Processing\n",
    "The second and the most important step — clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "In scikit-learn, CountVectorizer is a good tool to help us construct the Bag-of-words model that encoding data into the vector form.\n",
    "\n",
    "Back to amazon dataset, ConuntVectorizer will do the pre-processing on text data before creating the vector, which we mentioned at the beginning of this section. Thus, we don’t need to clean data by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 65859)\t1\n",
      "  (0, 36598)\t1\n",
      "  (0, 5997)\t1\n",
      "  (0, 40329)\t1\n",
      "  (0, 35894)\t2\n",
      "  (0, 61066)\t1\n",
      "  (0, 30559)\t2\n",
      "  (0, 36134)\t1\n",
      "  (0, 60126)\t2\n",
      "  (0, 10581)\t1\n",
      "  (0, 1866)\t1\n",
      "  (0, 41680)\t2\n",
      "  (0, 31085)\t1\n",
      "  (0, 20918)\t1\n",
      "  (0, 14586)\t1\n",
      "  (0, 67104)\t1\n",
      "  (0, 4831)\t1\n",
      "  (0, 6366)\t1\n",
      "  (0, 25374)\t1\n",
      "  (0, 3893)\t1\n",
      "  (0, 27782)\t1\n",
      "  (0, 52861)\t1\n",
      "  (0, 60850)\t1\n",
      "  (0, 26754)\t1\n",
      "  (0, 38671)\t1\n",
      "  :\t:\n",
      "  (208988, 32476)\t1\n",
      "  (208988, 28397)\t1\n",
      "  (208988, 32452)\t1\n",
      "  (208988, 11712)\t1\n",
      "  (208988, 35223)\t1\n",
      "  (208988, 53637)\t1\n",
      "  (208988, 59931)\t1\n",
      "  (208988, 33336)\t1\n",
      "  (208988, 35508)\t1\n",
      "  (208988, 66626)\t1\n",
      "  (208988, 9373)\t1\n",
      "  (208988, 59347)\t1\n",
      "  (208988, 2089)\t4\n",
      "  (208988, 39779)\t1\n",
      "  (208988, 24409)\t1\n",
      "  (208988, 61999)\t1\n",
      "  (208988, 3101)\t1\n",
      "  (208988, 10412)\t1\n",
      "  (208988, 29546)\t1\n",
      "  (208988, 23365)\t1\n",
      "  (208988, 65028)\t1\n",
      "  (208988, 12165)\t1\n",
      "  (208988, 46727)\t1\n",
      "  (208988, 2989)\t1\n",
      "  (208988, 39563)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# take a word as a token.\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b') \n",
    "# Learn the vocabulary dictionary and return term-document matrix.\n",
    "train_vector = vectorizer.fit_transform(train_X[\"reviewText\"])\n",
    "print(train_vector)\n",
    "# the vocabulary dictionary\n",
    "test_vector = vectorizer.transform(test_X[\"reviewText\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action', 'and', 'horror', 'joe', 'john', 'likes', 'mary', 'movies', 'only', 'to', 'too', 'watch']\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 7)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 7)\t2\n",
      "  (2, 3)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_X1 = [\"John likes to watch movies\",\n",
    "           \"Mary likes movies too\", \n",
    "           \"Joe only likes horror movies and action movies\"]\n",
    "\n",
    "vectorizer1 = CountVectorizer(token_pattern=r'\\b\\w+\\b') # take a word as a token.\n",
    "train_vector1 = vectorizer1.fit_transform(train_X1) # Learn the vocabulary dictionary and return term-document matrix.\n",
    "token_set1 = vectorizer1.get_feature_names() # the vocabulary dictionary: ['action', 'and', 'horror', 'joe', 'john', 'likes', 'mary', 'movies', 'only', 'to', 'too', 'watch']\n",
    "print(token_set1)\n",
    "print(train_vector1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "test_X1 = [\"Jay likes romantic movies\"]\n",
    "test_vector1 = vectorizer1.transform(test_X1)\n",
    "print(test_vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step — Model Constructing\n",
    "For the classification problem, we use the popular model — Logistic Regression for demonstration. Below shows how we utilize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9313275149288011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clr = LogisticRegression()\n",
    "clr.fit(train_vector, train_y.values.ravel())\n",
    "scores = clr.score(test_vector, test_y) # accuracy\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
